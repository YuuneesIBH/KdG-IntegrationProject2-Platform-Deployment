---
# API Gateway for Team 4
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-gateway-deployment
  namespace: ai-platform-team4
spec:
  replicas: 1
  selector:
    matchLabels:
      app: api-gateway
  template:
    metadata:
      labels:
        app: api-gateway
    spec:
      containers:
      - name: api-gateway
        image: nginx:1.27.4-alpine
        ports:
        - containerPort: 80
        volumeMounts:
        - name: nginx-config
          mountPath: /etc/nginx/nginx.conf
          subPath: nginx.conf
        - name: nginx-config
          mountPath: /etc/nginx/conf.d/default.conf
          subPath: default.conf
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
        livenessProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: nginx-config
        configMap:
          name: gateway-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: gateway-config
  namespace: ai-platform-team4
data:
  nginx.conf: |
    user nginx;
    worker_processes auto;
    error_log /var/log/nginx/error.log warn;
    pid /var/run/nginx.pid;

    events {
      worker_connections 1024;
    }

    http {
      include /etc/nginx/mime.types;
      default_type application/octet-stream;

      log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

      access_log /var/log/nginx/access.log main;

      sendfile on;
      tcp_nopush on;
      tcp_nodelay on;
      keepalive_timeout 65;

      include /etc/nginx/conf.d/*.conf;
    }

  default.conf: |
    upstream chatbot_rag {
      server chatbot-rag-service:8000;
    }

    upstream ai_player {
      server ai-player-service:8000;
    }

    upstream ollama {
      server ollama-service:11434;
    }

    server {
      listen 80;
      server_name _;
      client_max_body_size 50M;

      # Health check endpoint
      location /health {
        access_log off;
        return 200 '{"status": "healthy", "service": "api-gateway"}';
        add_header Content-Type application/json;
      }

      # Chatbot/RAG API endpoints - direct proxy without path rewrite
      # The app has routes at /api/chat, /api/docs, /api/openapi.json
      location /api/chat {
        proxy_pass http://chatbot_rag;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Streaming support for LLM responses
        proxy_buffering off;
        proxy_cache off;
        proxy_read_timeout 300s;
        proxy_connect_timeout 75s;
        chunked_transfer_encoding on;
      }

      # Chatbot docs/swagger
      location /api/docs {
        proxy_pass http://chatbot_rag;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
      }

      location /api/openapi.json {
        proxy_pass http://chatbot_rag;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
      }

      # Legacy /api/rag/ path (redirects to /api/)
      location /api/rag/ {
        rewrite ^/api/rag/(.*) /api/$1 break;
        proxy_pass http://chatbot_rag;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Streaming support
        proxy_buffering off;
        proxy_cache off;
        proxy_read_timeout 300s;
      }

      # AI Player API endpoints
      location /api/ai-player/ {
        rewrite ^/api/ai-player/(.*) /$1 break;
        proxy_pass http://ai_player;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
      }

      # Direct Ollama access (for debugging/admin)
      location /ollama/ {
        rewrite ^/ollama/(.*) /$1 break;
        proxy_pass http://ollama;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Streaming support
        proxy_buffering off;
        proxy_cache off;
        proxy_read_timeout 600s;
      }

      # Root - API info
      location / {
        return 200 '{"service": "Team 4 AI Platform API Gateway", "endpoints": ["/api/docs (Chatbot Swagger)", "/api/chat (POST)", "/api/ai-player/", "/ollama/", "/health"]}';
        add_header Content-Type application/json;
      }
    }
---
apiVersion: v1
kind: Service
metadata:
  name: api-gateway
  namespace: ai-platform-team4
  labels:
    app: api-gateway
spec:
  selector:
    app: api-gateway
  ports:
  - port: 80
    targetPort: 80
    protocol: TCP
    name: http
  type: LoadBalancer
